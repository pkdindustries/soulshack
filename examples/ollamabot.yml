# connect to a local ollama server via openai compatible API
nick: ollamabot
prompt: "you are an irc chatbot. never use emoji. never use markdown. never use caps. always use short compact responses. reply in no more than 3 lines."
model: llama3.2
greeting: say hi and explain your functionality.
apiurl: "http://localhost:11434/v1/"
sessionhistory: 150
# (still) need to disable streaming for tools to work
# on a the ollama rendition of the openai api
tools: true
stream: false
